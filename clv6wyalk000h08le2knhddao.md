---
title: "Où pointer le nez dans l'IA générative ?"
datePublished: Fri Apr 19 2024 16:57:23 GMT+0000 (Coordinated Universal Time)
cuid: clv6wyalk000h08le2knhddao
slug: ou-pointer-le-nez-dans-lia-generative
tags: ai-hacker

---

Il ne fait aucun doute que l'IA générative charrie énormément de passions médiatiques et affairistes. C'est le champ qui mobilise actuellement le plus gros des fonds, que ce soit les VC ou les grosses entreprises. Et c'est actuellement le champ où vous pouvez vous faire rapidement de l'argent si votre idée apparaît fort intéressante.

Il y a quelques jours, j'avais publié dans la newsletter "La Lettre de l'IA" portant sur l'actualité de l'IA que j'anime une analyse de ce que j'observais des experts de l'IA, des experts bien reconnus et crédibles. Et j'avais constaté pour ces experts des débouchés comme des chaînes Youtube, des livres, des cours payants, des newsletters à Substack ou Beehiv par exemple...etc. La consécration était de décrocher un emploi chez un cador de l'IA comme OpenAI, Cohere, Anthropic et autres. Ou encore chez une grande entreprise comme Meta, Google, Microsoft, Amazon, Apple et autres qui investissent énormément dans l'IA. C'était leur trajectoire pour la plupart d'entre eux.

Il faut aussi noter que certains experts se sont dirigés vers la création de startups et à moins d'être un virtuose de la levée des fonds et partenariats comme le font si bien OpenAI, Mistral, Anthropic et autres, vous n'avez aucune chance. De plus, même les experts et développeurs qui ont créé des startups qui sont des "wrappers" des modèles d'IA, qui utilisent les API de ces modèles pour leurs startups sont en difficulté par rapport à leur business model.

Si je fais toutes ces analyses, c'est parce que je ne veux pas avoir le menton sous le guidon. Je peux bien faire le travail que j'entreprends sur les abstractions avec la modularité dans l'IA et à la fin finir comme ces experts, en allant lancer une chaîne Youtube ou une newsletter en comptant sur le sponsoring, ou passant mon temps à publier des tutoriels, des cours et autres dans l'espoir de décrocher plus tard un emploi, ou même en lançant une startup. Pourtant je sais que les taux de réussite sont extrêmement minimes. Je risque de subir le même sort que j'ai subi en me lançant le menton sous le guidon avec le développement. Même en recourant aux certifications, j'ai été confronté à la dure réalité de ce milieu et les compressions qui frappent ce secteur depuis près de 4 ans n'ont rien arrangé.

Bien sûr qu'il faut renforcer mon expertise sans toutefois perdre de vue que ça ne sera pas suffisant pour décrocher le jackpot. C'est une condition parmi tant d'autres. Et il ne faudrait pas que je l'oublie. Si l'expertise suffisait seulement, c'est que les experts actuels auraient mieux monétisé leurs connaissances. Et si je dois m'en tenir à la réalité comme je le proclame, je n'ai ni leur parcours, ni leur expérience, ni même la crédibilité. Autant mieux rechercher d'autres leviers.

Pour déceler d'autres leviers, il faut d'abord une vue d'ensemble du champ. L'IA générative tourne autour de quelques acteurs qui surfent sur plusieurs couches :

* Une couche qui porte sur l'infrastructure d'IA : c'est là où on trouve les centres de données(data centers), les puces GPU, les données d'entraînement des modèles (et leur qualité). Ici, vous n'entendrez que des grands noms, les entreprises avec des poches bien profondes, capables de mobiliser des sommes astronomiques... Meta, Google, Amazon, Microsoft, Amazon, Nvidia,..etc.
    
* Une couche qui porte sur les modèles fondationnels d'IA : c'est là où on trouve ce qui est communément codifié par le terme "LLM" ou francisé par modèles larges de langage. Bien que ces modèles aient été popularisé par le "texte" à travers un chatbot comme ChatGPT, on assiste à des variantes multimodales qui sortent de plus en plus. L'objectif serait de couvrir le texte, l'image, le son et la vidéo. Il y a aussi une démarcation entre les modèles opensouce et les modèles commerciaux.
    
* On a aussi une couche qui porte sur les applications avec des centaines de startups qui s'appuient sur les API proposées par les LLM pour proposer des fonctionnalités par exemple de génération de texte ou d'images, de résumés, de classification, de recommandation ou autres dans des secteurs variés. Ici, on peut dire prosaïquement que ça naît et ça meurt tous les jours. C'est extrêmement risqué de ce côté.
    

C'est vrai que cette présentation est très simplifiée et si vous allez dans le fond, on ne peut pas limiter le champ de l'IA à ces trois (03) couches. On a bien des entreprises comme Lambda Labs qui, dans la couche "infrastructure", propose des offres axées sur le temps d'utilisation des GPU, comme les entreprises de cloud (AWS, Google ou Microsoft) qui proposent ce genre de service et vont même plus loin en assurant la distribution des modèles d'IA. Vous trouverez aussi plein d'entreprises qui offrent les applications, les frameworks pour entraîner vos modèles, les personnaliser (fine tuning), les préparer pour l'inférence et même les "monitorer" lorsqu'ils sont en production avec tout ce qui va avec (sécurité, logging, mises à jour,...etc). Le champ est très grand mais ce n'est pas ce qui m'intéresse.

Mon intérêt principal est de regarder ce champ et savoir comment me positionner et ce n'est pas chose facile. La couche "infrastructure" est inaccessible. Vous n'y trouverez aucun solopreneur. Pareil pour la couche "LLM". Par contre, vous allez quelques solopreneurs dans la couche "applications" avec tous les risques que cela comporte. Je dis bien "quelques" car il y a peu, très peu.

J'ai plutôt l'impression et ce n'est qu'une impression, que je dois me concentrer sur les données, les données d'entraînement des modèles d'IA. C'est là le nerf de la guerre comme on dit. Dans l'IA, on a les données, les algorithmes, la puissance de calcul et tout l'expertise dans le développement des solutions acquise avec l'ingénierie logicielle. Donc les experts dans ces domaines, on en trouve. Néanmoins, s'il y a un domaine qui attire peu les experts, c'est celui des données. Et justement ces experts s'accordent à dire que la qualité d'un modèle est aussi fonction des données... "Garbage in, Garbage out" dit-on. Je vais donc plutôt m'orienter dans ce domaine et j'ai en tête une entreprise comme Scale AI qui, bien que discrète, fournit en réalité toute l'infrastructure nécessaire pour les données d'entraînement de presque tous les cadors de l'IA générative. Je peux prendre cette option en ciblant une niche et une zone géographique. Après, pourquoi ne pas faire du "fine tuning" avec un modèle open source et monter une solution là dedans ? Un modèle léger, compact mais avec de bonnes données d'entraînement ? Je préfère m'arrêter là dessus.

Je vais donc continuer mes recherches sur l'approche modulaire mais pour ne pas tomber dans le piège de la tête sous le guidon, je vais expérimenter cette stratégie et je verrais ce que ça va donner. Comme je le dis depuis le lancement de ce blog, c'est le bon moment pour expérimenter. Et plus le temps passe, plus la fenêtre d'opportunité se réduit. 2024 est la bonne année pour l'IA-Jackpot.